{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "import numpy as np; np.set_printoptions(linewidth=130);\n",
    "# first we need a bit of import boilerplate\n",
    "import os\n",
    "import sys\n",
    "from sys import platform\n",
    "if platform == 'win32':\n",
    "    sys.path.append('D:/Brain_Network/Code/')\n",
    "    manifest_path = 'D:/Brain_Network/Data/Allen_Institute_Dataset/manifest.json'\n",
    "    project_dir = 'D:/Brain_Network/'\n",
    "elif platform =='darwin':\n",
    "    sys.path.append('/Users/chenyu/Workspace/Brain_Network/Code/')\n",
    "    manifest_path = '/Users/chenyu/Workspace/Brain_Network/Data/Allen_Institute_Dataset/manifest.json'\n",
    "    project_dir = '/Users/chenyu/Workspace/Brain_Network/'\n",
    "elif platform == 'linux':\n",
    "    sys.path.append('/home/yuchen/workspace/Brain_Network/Code/')\n",
    "    manifest_path = '/home/yuchen/workspace/Brain_Network/Data/Allen_Institute_Dataset/manifest.json'\n",
    "    project_dir = '/home/yuchen/workspace/Brain_Network/'\n",
    "else:\n",
    "    print('Add new computer system settings.')\n",
    "\n",
    "import numpy as np; np.set_printoptions(linewidth=110);\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import seaborn\n",
    "from tqdm.notebook import trange\n",
    "import time\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys.ecephys_session import EcephysSession\n",
    "\n",
    "# tell pandas to show all columns when we display a DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import hierarchical_model_generator\n",
    "import hierarchical_sampling_model\n",
    "import samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd 1.1.1\n",
      "allensdk 2.2.0\n",
      "h5py 2.8.0\n",
      "pynwb 1.4.0\n",
      "hdmf 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('pd', pd.__version__)\n",
    "import allensdk\n",
    "print('allensdk', allensdk.__version__)\n",
    "import h5py\n",
    "print('h5py', h5py.__version__)\n",
    "import pynwb\n",
    "print('pynwb', pynwb.__version__)\n",
    "import hdmf\n",
    "print('hdmf', hdmf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical model Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tamplate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = [\n",
    "'HBM_checkpoint_B_MC_0_500ms_probeCE_condition1_20200813-092937_generator_template.pkl',\n",
    "'HBM_checkpoint_BSS_MC_0_500ms_probeCE_o225_270_f8_20200801-174224_generator_template.pkl',\n",
    "'HBM_checkpoint_BSS_MC_0_500ms_probeCDE_o225_270_f8_20200731-125456_generator_template.pkl',\n",
    "'798911424_checkpoints_batch5_20201111-121627_generator_template.pkl', # B A3\n",
    "'798911424_checkpoints_batch14_20201023-042306_generator_template.pkl']  # BSS A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- 0 --------------------\n",
      "model_feature_type: BSS\n",
      "\n",
      "num areas 3   num trials 180   num conditions 1   num qs 3\n",
      "Model feature type:  BSS\n",
      "Condition: 0  stimulus_condition_id:0.0\n",
      "probeC g:[2 1 0] counts:[38 32 24]  probeD g:[2 1 0] counts:[31 27 20]  probeE g:[2 1 0] counts:[36 31 22]  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e4fc485ddb4a4bb9af0d6db32244e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Drawing q_cnd samples runs out of iterations.\n",
      "[ 0.22400341  0.00157317 -0.07157653  0.06505702  0.0507708  -0.02607444  0.37064867 -0.0058803  -0.03846866]\n"
     ]
    }
   ],
   "source": [
    "def runner(random_seed):\n",
    "    print(f'---------------------- {random_seed} --------------------')\n",
    "    ## Load simulation\n",
    "    generator_model = hierarchical_model_generator.HierarchicalModelGenerator()\n",
    "    data_folder = project_dir + 'Output/simulation/'\n",
    "    file_path = (data_folder + model_files[4])\n",
    "    generator_model.load_model(file_path)\n",
    "\n",
    "    np.random.seed(random_seed)  # Random seed for pseudo data.\n",
    "    model_feature_type = 'BSS'\n",
    "    generator_model.initial_step(model_feature_type=model_feature_type, num_trials=180, num_conditions = 1)\n",
    "\n",
    "    # Load samples. Only used for lambda variations.\n",
    "    # generator_model.samples = samples.Samples()\n",
    "    # load_dir = project_dir + 'Output/simulation/BSS_A3_R180_samples/'\n",
    "    # generator_model.samples.load_batches(load_dir, start_id=6, end_id=10, thin_step=1)\n",
    "\n",
    "    ## Generate data\n",
    "    select_clist = [4]\n",
    "    generator_model.generate_mu_sigma(sample_type='fixed', verbose=False)\n",
    "    generator_model.generate_q()\n",
    "    generator_model.generate_f_pop_gac(select_clist=select_clist, same_as_cross=False, verbose=False)\n",
    "    generator_model.generate_z(verbose=False)\n",
    "    generator_model.generate_p_gac(verbose=False)\n",
    "    generator_model.generate_log_lambda_nargc(variation='laplacian', laplacian_scalar=40, verbose=False)\n",
    "    generator_model.generate_spikes(verbose=False)\n",
    "\n",
    "    ## Prepare for the data fitting.\n",
    "    trial_time_window=generator_model.trial_time_window\n",
    "    spike_train_time_line = generator_model.spike_train_time_line\n",
    "    spike_trains, spike_times = generator_model.spike_trains, generator_model.spike_times\n",
    "    session = None\n",
    "    spike_counts, spike_shifts = generator_model.spike_counts, generator_model.spike_shifts\n",
    "    units_probes = generator_model.selected_units['probe_description']\n",
    "    probes = generator_model.probes\n",
    "    selected_units = generator_model.selected_units\n",
    "    trials_indices = generator_model.trials_indices\n",
    "    trials_groups = generator_model.trials_groups\n",
    "\n",
    "    ## Initial HBM\n",
    "    np.random.seed(0)  # Random seed for MCMC chain.\n",
    "    model = hierarchical_sampling_model.HierarchicalSamplingModel(session)\n",
    "    model.initial_step(spike_trains, spike_times, spike_train_time_line, selected_units, trials_groups,\n",
    "                       trial_time_window, probes=['probeC', 'probeD', 'probeE'], num_areas=3, num_groups=3, \n",
    "                       model_feature_type='BSS', prior_type='diag',\n",
    "                       eta_smooth_tuning=3e-8, verbose=False)\n",
    "    # Initialize with true values.\n",
    "    model.set_model(generator_model, select_clist=select_clist)\n",
    "\n",
    "    ##\n",
    "    clist = [0]\n",
    "    thin_begin = 0\n",
    "    thin_step = 1\n",
    "\n",
    "    t = trange(0, 2000)\n",
    "    for itr in t:\n",
    "        slc = (itr >= thin_begin) and (itr % thin_step == 0)\n",
    "        for c in clist:\n",
    "            if itr < 30:\n",
    "                model.update_f_local_pop_cag(c, sample_type='fit', verbose=False)\n",
    "                model.update_f_cross_pop_ca(c, sample_type='fit', record=(c==clist[-1] and slc), verbose=False)\n",
    "            if itr > 30:\n",
    "                model.update_f_local_pop_cag(c, sample_type='sample', verbose=False)\n",
    "                model.update_f_cross_pop_ca(c, sample_type='sample', record=(c==clist[-1] and slc), verbose=False)\n",
    "            model.update_q_arc(c, sample_type='sample', proposal_scalar=0.02, fit_peak_ratio=0,\n",
    "                               record=(c==clist[-1] and slc), verbose=False)  # proposal_scalar=0.1 BA2  0.04 BSS A3\n",
    "            if itr > 200 and itr % 10 == 0:\n",
    "                model.update_z_ngac(c, sample_type='sample', record=(c==clist[-1]), verbose=False)\n",
    "            if itr > 200:\n",
    "                model.update_p_gac(c, sample_type='sample', record=(c==clist[-1] and slc), verbose=False)\n",
    "        if itr > 200:\n",
    "            model.update_mu_simga(clist=clist, sample_type='iw_sample', record=slc, verbose=False)\n",
    "        model.complete_log_likelihood(clist)\n",
    "        t.set_description(f'{model.samples.log_likelihood[-1]:.2f} | {model.samples.q_accept_ratio_mean:.3f}')\n",
    "\n",
    "\n",
    "    ## Output\n",
    "    model.samples.plot_log_likelihood()\n",
    "    error_rnd, error_hat, error_fix, CI_trap_rnd, CI_trap_hat, CI_trap_fix = model.samples.rho_mse_ci_coverage(\n",
    "        burn_in=0, end=None, step=1, rho_type=['marginal', 'corrcoef'], true_model=generator_model, \n",
    "        model_feature_type=model.model_feature_type, verbose=True)\n",
    "    # print(CI_trap_hat)\n",
    "    print(CI_trap_rnd)\n",
    "    print(CI_trap_fix)\n",
    "    model.samples.plot_marginal_correlation(0, 1, burn_in=0, end=None, step=1, plot_type='rho',\n",
    "            true_model=generator_model, model_feature_type=model.model_feature_type,\n",
    "            distribution_type='hist')\n",
    "\n",
    "    # Save data.\n",
    "    experiment_name = f'{model_feature_type}_0_500ms_probe3_R{len(trials_indices)}_'\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_folder = project_dir + 'Output/simulation_output/BSS_A3_R180_laplacian40_variation_diag_prior_fixed_sigma_df10/'\n",
    "\n",
    "    # Save estimated model.\n",
    "    prefix = f'HBM_checkpoint_seed{random_seed}_'\n",
    "    file_path = output_folder + prefix + experiment_name + timestr + '.pkl'\n",
    "    model.save_model(save_data=False, file_path=file_path)\n",
    "    # Save true model.\n",
    "    prefix = f'HBM_generator_seed{random_seed}_'\n",
    "    file_path = output_folder + prefix + experiment_name + timestr + '.pkl'\n",
    "    generator_model.save_data(save_spikes=False, file_path=file_path)\n",
    "    # Save samples.\n",
    "    prefix = f'HBM_samples_seed{random_seed}_'\n",
    "    file_path = output_folder + prefix + experiment_name + timestr + '.pkl'\n",
    "    model.samples.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_range = trange(1, 50)\n",
    "for random_seed in seed_range:\n",
    "    runner(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "allensdk",
      "language": "python",
      "name": "allensdk"
     }
    },
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
     }
    }
   ],
   "remote_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "py37",
      "language": "python",
      "name": "py37"
     }
    },
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
     }
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
